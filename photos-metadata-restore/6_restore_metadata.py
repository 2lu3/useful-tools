#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å¾©å…ƒã—ã¦ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import datetime
import json
import os
import pickle
import multiprocessing
from dataclasses import dataclass
from pathlib import Path
import shutil
from typing import Any, Dict, List, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor

import exiftool
from alive_progress import alive_bar
from loguru import logger

from utils.exif_utils import GPSData, PhotoMetadata




def load_metadata() -> Tuple[List[PhotoMetadata], List[PhotoMetadata]]:
    """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    with open("output/photo_metadata.pkl", 'rb') as f:
        photo_metadata = pickle.load(f)
    
    with open("output/supplemental_metadata.pkl", 'rb') as f:
        supplemental_metadata = pickle.load(f)
    
    return photo_metadata, supplemental_metadata


def load_pair_data() -> Dict[str, Dict]:
    """pair.jsonãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    with open("output/pair.json", 'r', encoding='utf-8') as f:
        pair_data = json.load(f)
    
    # ãƒãƒƒã‚·ãƒ¥å€¤ã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–
    hash_to_pair = {}
    for pair in pair_data:
        hash_to_pair[pair['hash']] = pair
    
    return hash_to_pair


def write_exif_data(
    image_path: Path,
    datetime_to_write: Optional[datetime.datetime],
    gps_to_write: Optional[GPSData],
) -> bool:
    """ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã«EXIFãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãè¾¼ã‚€"""
    with exiftool.ExifTool() as et:
            # æ—¥æ™‚ãƒ‡ãƒ¼ã‚¿ã®æ›¸ãè¾¼ã¿
            if datetime_to_write:
                datetime_str = datetime_to_write.strftime("%Y:%m:%d %H:%M:%S")
                # EXIFãƒ‡ãƒ¼ã‚¿ã®æ›¸ãè¾¼ã¿
                et.execute(
                    f"-EXIF:DateTime={datetime_str}",
                    f"-EXIF:DateTimeOriginal={datetime_str}",
                    f"-EXIF:DateTimeDigitized={datetime_str}",
                    str(image_path),
                )

            # GPSãƒ‡ãƒ¼ã‚¿ã®æ›¸ãè¾¼ã¿
            if gps_to_write:
                # ç·¯åº¦ãƒ»çµŒåº¦ã‚’åº¦åˆ†ç§’å½¢å¼ã«å¤‰æ›
                lat_deg, lat_min, lat_sec = _decimal_to_dms(gps_to_write.latitude)
                lon_deg, lon_min, lon_sec = _decimal_to_dms(gps_to_write.longitude)

                lat_ref = "N" if gps_to_write.latitude >= 0 else "S"
                lon_ref = "E" if gps_to_write.longitude >= 0 else "W"

                et.execute(
                    f"-EXIF:GPSLatitude={lat_deg}deg {lat_min}' {lat_sec:.2f}\"",
                    f"-EXIF:GPSLatitudeRef={lat_ref}",
                    f"-EXIF:GPSLongitude={lon_deg}deg {lon_min}' {lon_sec:.2f}\"",
                    f"-EXIF:GPSLongitudeRef={lon_ref}",
                    str(image_path),
                )

                # é«˜åº¦ã®æ›¸ãè¾¼ã¿
                if gps_to_write.altitude is not None:
                    et.execute(
                        f"-EXIF:GPSAltitude={gps_to_write.altitude}",
                        f"-EXIF:GPSAltitudeRef=0",  # 0 = above sea level
                        str(image_path),
                    )

    return True


def _decimal_to_dms(decimal_deg: float) -> Tuple[int, int, float]:
    """10é€²æ•°åº¦ã‚’åº¦åˆ†ç§’ã«å¤‰æ›ã™ã‚‹"""
    degrees = int(abs(decimal_deg))
    minutes_float = (abs(decimal_deg) - degrees) * 60
    minutes = int(minutes_float)
    seconds = (minutes_float - minutes) * 60
    return degrees, minutes, seconds


def restore_metadata_for_image(
    filename: str,
    photo_data: PhotoMetadata,
    supplemental_data: Optional[PhotoMetadata],
    output_path: Path,
) -> None:
    """å˜ä¸€ç”»åƒã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å¾©å…ƒã‚’å®Ÿè¡Œã™ã‚‹"""
    image_path = output_path / "images" / filename

    
    # æ—¥æ™‚æƒ…å ±ã®å¾©å…ƒï¼ˆphotoãƒ‡ãƒ¼ã‚¿ã‚’å„ªå…ˆã€ãªã‘ã‚Œã°supplementalãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
    if photo_data.exif_datetime is not None and photo_data.exif_gps is not None:
        # ä¸¡æ–¹å­˜åœ¨ã™ã‚‹ã®ã§ã‚¹ã‚­ãƒƒãƒ—
        return
    # å¾©å…ƒã™ã‚‹æƒ…å ±ã‚’æ±ºå®š
    datetime_to_restore = None
    gps_to_restore = None
    
    if photo_data.exif_datetime is None:
        datetime_to_restore = supplemental_data.exif_datetime
    
    if photo_data.exif_gps is None:
        gps_to_restore = supplemental_data.exif_gps
   
    # EXIFãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãè¾¼ã¿
    if datetime_to_restore or gps_to_restore:
        write_exif_data(image_path, datetime_to_restore, gps_to_restore)

    # æ—¥æ™‚æƒ…å ±ãŒãªã„å†™çœŸã¯éš”é›¢ã™ã‚‹
    if datetime_to_restore is None:
        shutil.move(image_path, output_path / "images" / "no_datetime" / filename)
        return


def process_single_image(args):
    """å˜ä¸€ç”»åƒã®å‡¦ç†ï¼ˆä¸¦åˆ—å‡¦ç†ç”¨ï¼‰"""
    filename, photo_data, supplemental_data, output_path = args
    restore_metadata_for_image(filename, photo_data, supplemental_data, output_path)
    return filename


def process_all_images(
    photo_metadata: List[PhotoMetadata], 
    supplemental_metadata: List[PhotoMetadata], 
    output_path: Path,
    max_workers: Optional[int] = None
) -> None:
    """ã™ã¹ã¦ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å¾©å…ƒã‚’å®Ÿè¡Œã™ã‚‹ï¼ˆä¸¦åˆ—å‡¦ç†ï¼‰"""
    # ãƒãƒƒã‚·ãƒ¥ã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–
    photo_dict = {m.file_name: m for m in photo_metadata}
    supplemental_dict = {m.file_name: m for m in supplemental_metadata}
    
    total_files = len(photo_dict)
    
    if max_workers is None:
        max_workers = multiprocessing.cpu_count() * 2  # I/Oãƒã‚¦ãƒ³ãƒ‰ãªã®ã§CPUã‚³ã‚¢æ•°ã®2å€

    logger.info(f"ğŸ”§ {total_files}å€‹ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å¾©å…ƒã‚’é–‹å§‹ã—ã¾ã™... (ä¸¦åˆ—å‡¦ç†: {max_workers}ã‚¹ãƒ¬ãƒƒãƒ‰)")

    # ä¸¦åˆ—å‡¦ç†ç”¨ã®å¼•æ•°ã‚’æº–å‚™
    args_list = []
    for filename, photo_data in photo_dict.items():
        supplemental_data = supplemental_dict.get(filename)
        args_list.append((filename, photo_data, supplemental_data, output_path))

    with alive_bar(
        total_files, title="ğŸ“¸ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å¾©å…ƒä¸­ (ä¸¦åˆ—)", bar="smooth", spinner="dots_waves"
    ) as bar:
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # ä¸¦åˆ—å‡¦ç†ã‚’å®Ÿè¡Œ
            futures = [executor.submit(process_single_image, args) for args in args_list]
            
            for future in futures:
                filename = future.result()
                bar.text = f"âœ… å¾©å…ƒå®Œäº†: {filename}"
                bar()


def generate_summary_report(output_path: Path):
    """å¾©å…ƒçµæœã®ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹"""
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“Š ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å¾©å…ƒå®Œäº†")
    logger.info("=" * 60)
    logger.info("âœ… ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å¾©å…ƒãŒå®Œäº†ã—ã¾ã—ãŸ")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    # ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã‚’è¨­å®š
    script_dir = Path(__file__).parent
    base_path = script_dir
    output_path = base_path / "output"

    # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    assert base_path.exists(), f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{base_path}' ãŒå­˜åœ¨ã—ã¾ã›ã‚“"
    assert output_path.exists(), f"outputãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {output_path}"

    logger.info("ğŸš€ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å¾©å…ƒã‚’é–‹å§‹ã—ã¾ã™")

    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    photo_metadata, supplemental_metadata = load_metadata()
    
    logger.info(f"ğŸ“– ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    logger.info(f"  - photo_metadata: {len(photo_metadata)}ä»¶")
    logger.info(f"  - supplemental_metadata: {len(supplemental_metadata)}ä»¶")

    # ã™ã¹ã¦ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å¾©å…ƒã‚’å®Ÿè¡Œ
    process_all_images(photo_metadata, supplemental_metadata, output_path)

    # ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
    generate_summary_report(output_path)

    logger.info("âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å¾©å…ƒãŒå®Œäº†ã—ã¾ã—ãŸ")


if __name__ == "__main__":
    main()

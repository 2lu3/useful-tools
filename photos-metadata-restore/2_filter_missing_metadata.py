#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sys
from pathlib import Path
import datetime
from alive_progress import alive_bar
from loguru import logger
from typing import Optional, List, Dict, Tuple
from utils.exif_utils import get_exif_data, get_exif_datetime, get_gps_data, GPSData, PhotoMetadata
import json
import multiprocessing
from concurrent.futures import ThreadPoolExecutor
import shutil
from collections import defaultdict


def process_single_file(file_path: Path) -> PhotoMetadata:
    """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®EXIFãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    exif_data = get_exif_data(str(file_path))
    
    if exif_data is None:
        logger.error(f"EXIFãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        logger.error(f"exiftool {file_path}ã‚’å®Ÿè¡Œã—ã¦ã¿ã¦ãã ã•ã„")
        sys.exit(1)
    
    return PhotoMetadata(
        file_name=file_path.name,
        exif_datetime=get_exif_datetime(exif_data),
        exif_gps=get_gps_data(exif_data)
    )


def load_pair_mapping(base_path: Path) -> Dict[Path, List[Path]]:
    """pair.jsonã‹ã‚‰å¯¾å¿œé–¢ä¿‚ã‚’èª­ã¿è¾¼ã‚€"""
    pair_file = base_path / "output" / "pair.json"
    assert pair_file.exists()
    
    with open(pair_file, 'r', encoding='utf-8') as f:
        pair_data = json.load(f)
    
    mapping = {}
    for item in pair_data:
        destination = Path(item['destination'])
        sources = [Path(source) for source in item['sources']]
        mapping[destination] = sources
    
    logger.info(f"pair.jsonã‹ã‚‰{len(mapping)}å€‹ã®å¯¾å¿œé–¢ä¿‚ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    return mapping


def get_all_source_metadata(pair_mapping: Dict[Path, List[Path]]) -> Dict[str, PhotoMetadata]:
    """pair.jsonã‹ã‚‰èª­ã¿è¾¼ã‚“ã æƒ…å ±ã‚’ã‚‚ã¨ã«ã€å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã®metadataã‚’ã™ã¹ã¦å–å¾—ã™ã‚‹"""
    # ã™ã¹ã¦ã®å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†
    all_source_files = []
    for destination, sources in pair_mapping.items():
        all_source_files.extend(sources)
    
    logger.info(f"å…ƒãƒ•ã‚¡ã‚¤ãƒ«ç·æ•°: {len(all_source_files)}å€‹")
    
    # ä¸¦åˆ—å‡¦ç†ã§ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    max_workers = multiprocessing.cpu_count() * 2
    source_metadata = {}
    
    with alive_bar(len(all_source_files), title="ğŸ“¸ å…ƒãƒ•ã‚¡ã‚¤ãƒ«åˆ†æä¸­ (ä¸¦åˆ—)", bar='smooth', spinner='dots_waves') as bar:
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = [executor.submit(process_single_file, file_path) for file_path in all_source_files]
            
            for future in futures:
                metadata = future.result()
                source_metadata[metadata.file_name] = metadata
                bar.text = f"ğŸ” åˆ†æä¸­: {metadata.file_name[:50]}{'...' if len(metadata.file_name) > 50 else ''}"
                bar()
    
    return source_metadata


def merge_metadata_list(metadata_list: List[PhotoMetadata]) -> PhotoMetadata:
    """è¤‡æ•°ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã™ã‚‹"""
    if not metadata_list:
        raise ValueError("ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆãŒç©ºã§ã™")
    
    if len(metadata_list) == 1:
        return metadata_list[0]
    
    # æœ€åˆã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ™ãƒ¼ã‚¹ã«ã™ã‚‹
    merged = metadata_list[0]
    
    # GPSãƒ‡ãƒ¼ã‚¿ã®çµ±åˆ
    gps_data_list = [m.exif_gps for m in metadata_list if m.exif_gps is not None]
    if len(gps_data_list) > 1:
        # è¤‡æ•°ã®GPSãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã€ä¸€è‡´ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        first_gps = gps_data_list[0]
        for gps in gps_data_list[1:]:
            if (gps.latitude != first_gps.latitude or 
                gps.longitude != first_gps.longitude or 
                gps.altitude != first_gps.altitude):
                logger.error(f"GPSãƒ‡ãƒ¼ã‚¿ãŒä¸€è‡´ã—ã¾ã›ã‚“:")
                logger.error(f"  ãƒ•ã‚¡ã‚¤ãƒ«1: {metadata_list[0].file_name} - {first_gps}")
                logger.error(f"  ãƒ•ã‚¡ã‚¤ãƒ«2: {[m.file_name for m in metadata_list if m.exif_gps == gps][0]} - {gps}")
                sys.exit(1)
        merged.exif_gps = first_gps
    elif len(gps_data_list) == 1:
        # GPSãƒ‡ãƒ¼ã‚¿ãŒ1ã¤ã ã‘ã‚ã‚‹å ´åˆã€ãã‚Œã‚’ä½¿ç”¨
        merged.exif_gps = gps_data_list[0]
    
    # æ—¥æ™‚ãƒ‡ãƒ¼ã‚¿ã®çµ±åˆ
    datetime_list = [m.exif_datetime for m in metadata_list if m.exif_datetime is not None]
    if len(datetime_list) > 1:
        # è¤‡æ•°ã®æ—¥æ™‚ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã€ä¸€è‡´ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        first_datetime = datetime_list[0]
        for dt in datetime_list[1:]:
            if dt != first_datetime:
                logger.error(f"æ—¥æ™‚ãƒ‡ãƒ¼ã‚¿ãŒä¸€è‡´ã—ã¾ã›ã‚“:")
                logger.error(f"  ãƒ•ã‚¡ã‚¤ãƒ«1: {metadata_list[0].file_name} - {first_datetime}")
                logger.error(f"  ãƒ•ã‚¡ã‚¤ãƒ«2: {[m.file_name for m in metadata_list if m.exif_datetime == dt][0]} - {dt}")
                sys.exit(1)
        merged.exif_datetime = first_datetime
    elif len(datetime_list) == 1:
        # æ—¥æ™‚ãƒ‡ãƒ¼ã‚¿ãŒ1ã¤ã ã‘ã‚ã‚‹å ´åˆã€ãã‚Œã‚’ä½¿ç”¨
        merged.exif_datetime = datetime_list[0]
    
    return merged


def merge_all_metadata(pair_mapping: Dict[Path, List[Path]], source_metadata: Dict[str, PhotoMetadata]) -> List[PhotoMetadata]:
    """ã™ã¹ã¦ã®metadataã‚’çµ±åˆã™ã‚‹"""
    merged_metadata_list = []
    
    logger.info("ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿çµ±åˆä¸­...")
    with alive_bar(len(pair_mapping), title="ğŸ”„ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿çµ±åˆä¸­", bar='smooth', spinner='dots_waves') as bar:
        for destination, sources in pair_mapping.items():
            # ã“ã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾å¿œã™ã‚‹å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
            source_metadata_list = []
            for source in sources:
                source_name = source.name
                if source_name in source_metadata:
                    source_metadata_list.append(source_metadata[source_name])
                else:
                    logger.warning(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {source_name}")
            
            if source_metadata_list:
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ
                merged_metadata = merge_metadata_list(source_metadata_list)
                # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã«å¤‰æ›´
                merged_metadata.file_name = destination.name
                merged_metadata_list.append(merged_metadata)
                
                if len(source_metadata_list) > 1:
                    filename_short = destination.name[:40] + ('...' if len(destination.name) > 40 else '')
                    bar.text = f"ğŸ”„ çµ±åˆå®Œäº†: {len(source_metadata_list)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ« -> {filename_short}"
                else:
                    filename_short = destination.name[:40] + ('...' if len(destination.name) > 40 else '')
                    bar.text = f"âœ… å‡¦ç†å®Œäº†: {filename_short}"
            else:
                logger.error(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ: {destination}")
            
            bar()
    
    return merged_metadata_list


def filter_inconsistent_metadata(metadata_list: List[PhotoMetadata]) -> List[PhotoMetadata]:
    """æ—¥ä»˜ã‚„GPSãŒä¸€è‡´ã—ãªã„ã‚‚ã®ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹"""
    logger.info("ğŸ” ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™...")
    
    # æ—¥æ™‚ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    datetime_groups = defaultdict(list)
    files_without_datetime = []
    
    with alive_bar(len(metadata_list), title="ğŸ“Š æ—¥æ™‚ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ä¸­", bar='smooth', spinner='dots_waves') as bar:
        for metadata in metadata_list:
            if metadata.exif_datetime:
                datetime_groups[metadata.exif_datetime].append(metadata)
            else:
                files_without_datetime.append(metadata)
            bar.text = f"ğŸ“Š ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ä¸­: {metadata.file_name[:40]}{'...' if len(metadata.file_name) > 40 else ''}"
            bar()
    
    logger.info(f"æ—¥æ™‚ã‚°ãƒ«ãƒ¼ãƒ—æ•°: {len(datetime_groups)}")
    logger.info(f"æ—¥æ™‚ãªã—ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(files_without_datetime)}")
    
    # å„æ—¥æ™‚ã‚°ãƒ«ãƒ¼ãƒ—å†…ã§GPSãƒ‡ãƒ¼ã‚¿ã®ä¸€è²«æ€§ã‚’ãƒã‚§ãƒƒã‚¯
    consistent_metadata = []
    inconsistent_files = []
    
    total_groups = len(datetime_groups)
    with alive_bar(total_groups, title="ğŸ” GPSä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯ä¸­", bar='smooth', spinner='dots_waves') as bar:
        for datetime_obj, group in datetime_groups.items():
            if len(group) > 1:
                # åŒã˜æ—¥æ™‚ã«è¤‡æ•°ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã€GPSãƒ‡ãƒ¼ã‚¿ã‚’ãƒã‚§ãƒƒã‚¯
                gps_data_list = [m.exif_gps for m in group if m.exif_gps is not None]
                
                if len(gps_data_list) > 1:
                    # è¤‡æ•°ã®GPSãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã€ä¸€è‡´ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    first_gps = gps_data_list[0]
                    is_consistent = True
                    
                    for gps in gps_data_list[1:]:
                        if (gps.latitude != first_gps.latitude or 
                            gps.longitude != first_gps.longitude or 
                            gps.altitude != first_gps.altitude):
                            is_consistent = False
                            break
                    
                    if is_consistent:
                        # GPSãƒ‡ãƒ¼ã‚¿ãŒä¸€è‡´ã™ã‚‹å ´åˆã¯1ã¤ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒ
                        consistent_metadata.append(group[0])
                        bar.text = f"âœ… GPSä¸€è‡´: {group[0].file_name[:30]}{'...' if len(group[0].file_name) > 30 else ''}"
                    else:
                        # GPSãƒ‡ãƒ¼ã‚¿ãŒä¸€è‡´ã—ãªã„å ´åˆã¯ã™ã¹ã¦é™¤å¤–
                        inconsistent_files.extend(group)
                        logger.warning(f"æ—¥æ™‚ {datetime_obj} ã§GPSãƒ‡ãƒ¼ã‚¿ãŒä¸€è‡´ã—ã¾ã›ã‚“: {len(group)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é™¤å¤–")
                        bar.text = f"âš ï¸ GPSä¸ä¸€è‡´: {len(group)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é™¤å¤–"
                else:
                    # GPSãƒ‡ãƒ¼ã‚¿ãŒ1ã¤ã¾ãŸã¯0å€‹ã®å ´åˆã¯ä¿æŒ
                    consistent_metadata.append(group[0])
                    bar.text = f"âœ… å˜ä¸€GPS: {group[0].file_name[:30]}{'...' if len(group[0].file_name) > 30 else ''}"
            else:
                # å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯ä¿æŒ
                consistent_metadata.append(group[0])
                bar.text = f"âœ… å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«: {group[0].file_name[:30]}{'...' if len(group[0].file_name) > 30 else ''}"
            
            bar()
    
    # æ—¥æ™‚ãªã—ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚é™¤å¤–
    inconsistent_files.extend(files_without_datetime)
    logger.info(f"æ—¥æ™‚ãªã—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é™¤å¤–: {len(files_without_datetime)}å€‹")
    
    logger.info(f"ä¸€è²«æ€§ã®ã‚ã‚‹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {len(consistent_metadata)}å€‹")
    logger.info(f"é™¤å¤–ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«: {len(inconsistent_files)}å€‹")
    
    return consistent_metadata


def save_filtered_metadata(metadata_list: List[PhotoMetadata], base_path: Path) -> None:
    """ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸç”»åƒã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã™ã‚‹"""
    import pickle
    
    metadata_file = base_path / "output" / "photo_metadata.pkl"
    
    with open(metadata_file, 'wb') as f:
        pickle.dump(metadata_list, f)
    
    logger.info(f"ğŸ’¾ ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {metadata_file}")
    logger.info(f"ä¿å­˜ã•ã‚ŒãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ•°: {len(metadata_list)}å€‹")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•° - ã‚·ãƒ³ãƒ—ãƒ«ãª4ã‚¹ãƒ†ãƒƒãƒ—ã§å‡¦ç†"""
    script_dir = Path(__file__).parent
    base_path = script_dir
    output_path = base_path / "output"
    
    assert base_path.exists(), f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{base_path}' ãŒå­˜åœ¨ã—ã¾ã›ã‚“"
    assert output_path.exists(), f"outputãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {output_path}"
    
    # 1. pair.jsonã‹ã‚‰èª­ã¿è¾¼ã‚“ã æƒ…å ±ã‚’ã‚‚ã¨ã«ã€å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã®metadataã‚’ã™ã¹ã¦å–å¾—ã™ã‚‹
    logger.info("ğŸš€ === ã‚¹ãƒ†ãƒƒãƒ—1: å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾— ===")
    pair_mapping = load_pair_mapping(base_path)
    source_metadata = get_all_source_metadata(pair_mapping)
    
    # 2. ã™ã¹ã¦ã®metadataã‚’çµ±åˆã™ã‚‹
    logger.info("ğŸ”„ === ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿çµ±åˆ ===")
    merged_metadata = merge_all_metadata(pair_mapping, source_metadata)
    
    # 3. æ—¥ä»˜ã‚„GPSãŒä¸€è‡´ã—ãªã„ã‚‚ã®ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹
    logger.info("ğŸ” === ã‚¹ãƒ†ãƒƒãƒ—3: ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° ===")
    filtered_metadata = filter_inconsistent_metadata(merged_metadata)
    
    # 4. ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸç”»åƒã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã™ã‚‹
    logger.info("ğŸ’¾ === ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜ ===")
    save_filtered_metadata(filtered_metadata, base_path)
    
    logger.info("ğŸ‰ âœ… å…¨ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

if __name__ == "__main__":
    main()